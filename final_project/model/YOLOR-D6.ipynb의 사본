{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLOR-D6.ipynb의 사본","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"a7g5t_qH_lkr","executionInfo":{"status":"ok","timestamp":1639327547581,"user_tz":-540,"elapsed":539,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}}},"source":["import math\n","import matplotlib.pyplot as plt\n","from glob import glob\n","import yaml\n","import torch\n","import torch\n","from IPython.display import Image\n","import os"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVuSvpHLoqOE"},"source":["# YOLOR\n"]},{"cell_type":"markdown","metadata":{"id":"9Z4IuZIgnC2t"},"source":["[YOLOR이란](https://ichi.pro/ko/yoloreun-yolov4boda-ppaleugo-ppaleunayo-92913793395905)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUR3e_tRfDBr","executionInfo":{"status":"ok","timestamp":1639326380759,"user_tz":-540,"elapsed":19167,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"77b864b3-2bf6-4261-ac66-002ea54fb20d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"sknT_S1dQzmk"},"source":["# 코랩에도 도커???\n","# create the docker container, you can change the share memory size if you have more.\n","!nvidia-docker run --name yolor -it -v your_coco_path/:/coco/ -v your_code_path/:/yolor --shm-size=64g nvcr.io/nvidia/pytorch:20.11-py3\n","\n","# apt install required packages\n","!apt update\n","!apt install -y zip htop screen libgl1-mesa-glx\n","\n","# pip install required packages\n","!pip install seaborn thop\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vk06gpcnQqu"},"source":["# mish 활성화 함수 클론\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor\n","!git clone https://github.com/JunnYu/mish-cuda\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor/mish-cuda\n","!python setup.py build install\n","\n","# install pytorch_wavelets if you want to use dwt down-sampling module\n","# https://github.com/fbcotter/pytorch_wavelets\n","\n","\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor\n","!git clone https://github.com/fbcotter/pytorch_wavelets\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor/pytorch_wavelets\n","!pip install .\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-zSOjKppsQs","executionInfo":{"status":"ok","timestamp":1639327347289,"user_tz":-540,"elapsed":2154,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"39fef950-22b4-45c9-9888-836b961cc18c"},"source":["# yolor 클론\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor\n","!git clone https://github.com/WongKinYiu/yolor.git"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/성신/yolor\n","Cloning into 'yolor'...\n","remote: Enumerating objects: 489, done.\u001b[K\n","remote: Counting objects: 100% (222/222), done.\u001b[K\n","remote: Compressing objects: 100% (93/93), done.\u001b[K\n","remote: Total 489 (delta 184), reused 129 (delta 129), pack-reused 267\u001b[K\n","Receiving objects: 100% (489/489), 3.43 MiB | 8.35 MiB/s, done.\n","Resolving deltas: 100% (230/230), done.\n"]}]},{"cell_type":"code","metadata":{"id":"WLqmJb-QqXml"},"source":["!pip list | grep numpy\n","!pip list | grep pycocotools\n","!pip list | grep PyYAML\n","!pip list | grep opencv-python\n","!pip list | grep Pillow\n","!pip list | grep scipy\n","!pip list | grep tensorboard\n","!pip list | grep torch\n","!pip list | grep tqdm\n","!pip list | grep seaborn\n","!pip list | grep thop\n","!pip install Cython --install-option=\"--no-cython-compile\"\n","!pip install awscli\n","\n","!pip install PyYAML>=5.3.1\n","!pip install -U PyYAML"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jxGM_9hzwzBm","executionInfo":{"status":"ok","timestamp":1639327405384,"user_tz":-540,"elapsed":492,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"d10935a4-0d15-497c-efd4-638bed24d7ab"},"source":["%cd yolor"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/성신/yolor/yolor\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Dmw_MvWw92y","executionInfo":{"status":"ok","timestamp":1639327407515,"user_tz":-540,"elapsed":4,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"b05a845c-2bf5-4391-b77a-d0c3f2492b42"},"source":["%cd scripts"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/성신/yolor/yolor/scripts\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8r7YI8VMwmAs","executionInfo":{"status":"ok","timestamp":1639327421306,"user_tz":-540,"elapsed":13793,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"a5cdbf5d-1113-4186-c319-3423b5401827"},"source":["!bash get_pretrain.sh"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   408    0   408    0     0   1971      0 --:--:-- --:--:-- --:--:--  1980\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  142M  100  142M    0     0  31.0M      0  0:00:04  0:00:04 --:--:-- 51.7M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   408    0   408    0     0   2358      0 --:--:-- --:--:-- --:--:--  2358\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  305M  100  305M    0     0  34.8M      0  0:00:08  0:00:08 --:--:-- 40.5M\n"]}]},{"cell_type":"code","source":["yes_img = glob('/content/drive/MyDrive/final_project_team8/킥보드 탑승 예시사진/yes/*.jpg')\n","\n","# train\n","with open('/content/drive/MyDrive/final_project_team8/성신/yolor/yolor/data/train.txt', 'w') as f:\n","\tf.write('\\n'.join(yes_img) + '\\n')\n"," \n","\n","# valied\n","# with open('/content/drive/MyDrive/final_project_team8/성신/yolor/yolor/data/val.txt', 'w') as f:\n","# \tf.write('\\n'.join(valid_img_list) + '\\n')"],"metadata":{"id":"hlRIlccthNhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RN92DAstbvJR","executionInfo":{"status":"ok","timestamp":1639327833635,"user_tz":-540,"elapsed":1113,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"51dd7536-c0a4-4f58-b909-11806b414a44"},"source":["import torch\n","print('Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) \n","\n","if torch.cuda.is_available() \n","\n","else 'CPU'))"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Using torch 1.10.0+cu111 _CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhiQXxgYTp7G","executionInfo":{"status":"ok","timestamp":1639328032716,"user_tz":-540,"elapsed":3093,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"f9934b62-df13-4d2a-8e49-61d19ae2cc36"},"source":["!python train.py --batch-size 2 \\\n","--img 1280 1280 \\\n","--data ./data/custom.yaml \\\n","--cfg ./models/yolor-d6.yaml \\\n","--weights ./pre/yolor-d6.pt \\\n","--device 0 \\\n","--name yolord6 \\\n","--hyp data/hypscratch.yaml \\\n","--epochs 1\\\n"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"train.py\", line 506, in <module>\n","    opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n","  File \"/content/drive/.shortcut-targets-by-id/1cFF5_9im4PZ2gSNoqz18KLMltfsx9SK3/final_project_team8/성신/yolor/yolor/utils/general.py\", line 73, in check_file\n","    assert len(files), 'File Not Found: %s' % file  # assert file was found\n","AssertionError: File Not Found: ./data/custom.yaml\n"]}]},{"cell_type":"markdown","metadata":{"id":"V6vyU8kNom8L"},"source":["# 20 epochs"]},{"cell_type":"code","metadata":{"id":"ByyzQAu-H5Gu"},"source":["%cd /content/drive/MyDrive/final_project_team8/성신/yolor/mish-cuda\n","!python setup.py build install\n","%cd /content/drive/MyDrive/final_project_team8/성신/yolor/pytorch_wavelets\n","!pip install .\n","!pip install Cython --install-option=\"--no-cython-compile\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8NNRb11JlHI","executionInfo":{"status":"ok","timestamp":1637430927423,"user_tz":-540,"elapsed":1615,"user":{"displayName":"박준원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01666978145944503968"}},"outputId":"4524ab70-816a-4c27-85e5-f9d73cac8369"},"source":["%cd /content/drive/MyDrive/final_project_team8/성신/yolor/yolor"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/final_project_team8/현준/yolor/yolor\n"]}]},{"cell_type":"code","metadata":{"id":"K2JBYCJOotzV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639328606055,"user_tz":-540,"elapsed":542,"user":{"displayName":"성신","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3DYvWYn1gPb-VcIjVUL3X5SqrqjqEyd9JTOrpow=s64","userId":"14581914920101858851"}},"outputId":"d3ca3f46-4494-4407-8f05-9526d74077a1"},"source":["!python detect.py --weights best1119.pt \\\n","--img-size 448 \\\n","--conf 0.5 \\\n","--source /content/images.jpg"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["python3: can't open file 'detect.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"markdown","metadata":{"id":"DcmXhYUGOm5g"},"source":["# dd\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xw_jRgJ5P6mW","executionInfo":{"status":"ok","timestamp":1637397945789,"user_tz":-540,"elapsed":407,"user":{"displayName":"박준원","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01666978145944503968"}},"outputId":"3e347ef5-2006-4d0a-b269-4df6d442d06f"},"source":["cd /content/drive/MyDrive/final_project_team8/성신/yolor/yolor"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/final_project_team8/현준/yolor/yolor\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":292},"id":"rqF6QmQ-OoD3","executionInfo":{"status":"error","timestamp":1637377115026,"user_tz":-540,"elapsed":410,"user":{"displayName":"Junny hi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEjHl3iEZdmO8l2rmXULfbj0fk2N-XZ7NECIwjow=s64","userId":"11763536325377287333"}},"outputId":"cfa5ca50-d406-4a82-f0f1-b1052fb58c4b"},"source":["SOURCE = '/content/aa.jpg'\n","WEIGHTS = '/content/drive/MyDrive/final_project_team8/현준/yolor/yolor/best.pt'\n","IMG_SIZE = 416\n","DEVICE = ''\n","AUGMENT = False\n","CONF_THRES = 0.25\n","IOU_THRES = 0.45\n","CLASSES = None\n","AGNOSTIC_NMS = False\n","\n","\n","import argparse\n","import time\n","from pathlib import Path\n","\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, \\\n","    strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized\n","\n","\n","\n","def detect(save_img=False):\n","    out, source, weights, view_img, save_txt, imgsz = \\\n","        opt.output,opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size\n","\n","    # webcam = source == '0' or source.startswith('rtsp') or source.startswith('http') or source.endswith('.txt')\n","    webcam = False\n","\n","    # Initialize\n","    set_logging()\n","    device = select_device(opt.device)\n","    if os.path.exists(out):\n","        shutil.rmtree(out)  # delete output folder\n","    os.makedirs(out)  # make new output folder\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","    imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Second-stage classifier\n","    classify = False\n","    if classify:\n","        modelc = load_classifier(name='resnet101', n=2)  # initialize\n","        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model'])  # load weights\n","        modelc.to(device).eval()\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    if webcam:\n","        view_img = True\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz)\n","    else:\n","        save_img = True\n","        dataset = LoadImages(source, img_size=imgsz)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n","\n","    # Run inference\n","    t0 = time.time()\n","    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n","    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n","    for path, img, im0s, vid_cap in dataset:\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Inference\n","        t1 = time_synchronized()\n","        pred = model(img, augment=opt.augment)[0]\n","\n","        # Apply NMS\n","        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n","        t2 = time_synchronized()\n","\n","        # Apply Classifier\n","        if classify:\n","            pred = apply_classifier(pred, modelc, img, im0s)\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            if webcam:  # batch_size >= 1\n","                p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n","            else:\n","                p, s, im0 = path, '', im0s\n","\n","            save_path = str(Path(out) / Path(p).name)\n","            txt_path = str(Path(out) / Path(p).stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')\n","            s += '%gx%g ' % img.shape[2:]  # print string\n","            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","            if det is not None and len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results\n","                for c in det[:, -1].unique():\n","                    n = (det[:, -1] == c).sum()  # detections per class\n","                    s += '%g %ss, ' % (n, names[int(c)])  # add to string\n","\n","                # Write results\n","                for *xyxy, conf, cls in reversed(det):\n","                    if save_txt:  # Write to file\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        with open(txt_path + '.txt', 'a') as f:\n","                            f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n","\n","                    if save_img or view_img:  # Add bbox to image\n","                        label = '%s %.2f' % (names[int(cls)], conf)\n","                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n","\n","            # Print time (inference + NMS)\n","            print('%sDone. (%.3fs)' % (s, t2 - t1))\n","\n","            # Stream results\n","            if view_img:\n","                cv2.imshow(p, im0)\n","                if cv2.waitKey(1) == ord('q'):  # q to quit\n","                    raise StopIteration\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'images':\n","                    cv2.imwrite(save_path, im0)\n","                else:\n","                    if vid_path != save_path:  # new video\n","                        vid_path = save_path\n","                        if isinstance(vid_writer, cv2.VideoWriter):\n","                            vid_writer.release()  # release previous video writer\n","\n","                        fourcc = 'mp4v'  # output video codec\n","                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n","                    vid_writer.write(im0)\n","\n","    if save_txt or save_img:\n","        print('Results saved to %s' % Path(out))\n","        if platform.system() == 'Darwin' and not opt.update:  # MacOS\n","            os.system('open ' + save_path)\n","\n","    print('Done. (%.3fs)' % (time.time() - t0))\n","\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--weights', nargs='+', type=str, default='weights/yolov5s.pt', help='model.pt path(s)')\n","    # parser.add_argument('--source', type=str, default='inference/images', help='source')\n","    parser.add_argument('--source', type=str, default='test.mp4', help='source')  # file/folder, 0 for webcam\n","    parser.add_argument('--output', type=str, default='inference/output', help='output folder')  # output folder\n","    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n","    parser.add_argument('--conf-thres', type=float, default=0.4, help='object confidence threshold')\n","    parser.add_argument('--iou-thres', type=float, default=0.5, help='IOU threshold for NMS')\n","    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n","    # parser.add_argument('--view-img', action='store_true', help='display results')\n","    parser.add_argument('--view-img', default=True, help='display results')\n","    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n","    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n","    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n","    parser.add_argument('--augment', action='store_true', help='augmented inference')\n","    parser.add_argument('--update', action='store_true', help='update all models')\n","    opt = parser.parse_args()\n","    print(opt)\n","\n","    with torch.no_grad():\n","        detect()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher.py [-h] [--weights WEIGHTS [WEIGHTS ...]]\n","                             [--source SOURCE] [--output OUTPUT]\n","                             [--img-size IMG_SIZE] [--conf-thres CONF_THRES]\n","                             [--iou-thres IOU_THRES] [--device DEVICE]\n","                             [--view-img VIEW_IMG] [--save-txt]\n","                             [--classes CLASSES [CLASSES ...]]\n","                             [--agnostic-nms] [--augment] [--update]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-441b777d-9909-4d0f-960d-33ec1892d85b.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]}]}